{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a04142-3849-40e4-a445-9205518588c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/LMWee/Sensor_design/Long_Design_Shorten'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define working directory\n",
    "import os\n",
    "os.chdir('/Users/LMWee/Sensor_design/Long_Design_Shorten/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc6d10f-f91c-4204-9f9e-16476783a73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed designs: 30\n",
      "Skipped entries: 1 (see Trat1_skipped_designs.log)\n",
      "Wrote FASTA: Trat1_designs.fasta\n",
      "Wrote CSV: Trat1_designs.csv\n"
     ]
    }
   ],
   "source": [
    "# Jupyter-ready: mRNA -> designs pipeline (searches CCA, produces FASTA + CSV + skipped log)\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# User parameters / filenames\n",
    "# -----------------------------\n",
    "input_fasta = \"Trat1.fasta\"      # your input file\n",
    "output_fasta = \"Trat1_designs.fasta\"        # final accepted designs\n",
    "output_csv = \"Trat1_designs.csv\"            # CSV with columns: label, full_seq, aa_seq, region_class\n",
    "skipped_log = \"Trat1_skipped_designs.log\"   # human-readable log for skipped designs\n",
    "\n",
    "# Default adapters (user may override by setting user_prefix/user_suffix)\n",
    "default_prefix = \"CCTGGGCCGATTAAGGGCCTGCAGGGTGGA\"\n",
    "default_suffix = \"TCTACTCGAGGGGCTAGCCAGGGCAGCGGC\"\n",
    "user_prefix = None\n",
    "user_suffix = None\n",
    "\n",
    "# MS2 loop inserts (uppercase DNA)\n",
    "MS2_inserts = {\n",
    "    21: \"AGACATGAGGATCACCCATGT\",   # variant 1\n",
    "    47: \"GGGTGGAGGAACACCCCACCC\",   # variant 2\n",
    "    103: \"AGAAGCACCATCAGGGCTTCT\",  # variant 3\n",
    "    129: \"GCGTGGAGCATCAGCCCACGC\"   # variant 4\n",
    "}\n",
    "\n",
    "# BspQI / SapI recognition sequences (DNA-level)\n",
    "BspQI_sites = [\"GCTCTTC\", \"GAAGAGC\"]\n",
    "SapI_sites = [\"GCTCTTC\", \"GAAGAGC\"]\n",
    "FORBIDDEN_SITES = BspQI_sites + SapI_sites\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def check_adapter_validity(adapter_seq: str, adapter_name=\"Adapter\"):\n",
    "    \"\"\"Validate adapter: length multiple of 3, no in-frame stop (frame 0), no forbidden sites.\"\"\"\n",
    "    adapter_seq = adapter_seq.upper()\n",
    "    if len(adapter_seq) % 3 != 0:\n",
    "        raise ValueError(f\"{adapter_name} length ({len(adapter_seq)}) is not a multiple of 3\")\n",
    "    # check in-frame stop codons in frame 0\n",
    "    for i in range(0, len(adapter_seq)-2, 3):\n",
    "        codon = adapter_seq[i:i+3]\n",
    "        if codon in (\"TAG\", \"TAA\", \"TGA\"):\n",
    "            raise ValueError(f\"{adapter_name} contains stop codon {codon} at position {i} (frame 0)\")\n",
    "    # check forbidden sites anywhere in adapter\n",
    "    for site in FORBIDDEN_SITES:\n",
    "        if site in adapter_seq:\n",
    "            raise ValueError(f\"{adapter_name} contains forbidden site {site}\")\n",
    "    return True\n",
    "\n",
    "def dna_standardize(seq: str) -> str:\n",
    "    return str(seq).upper().replace(\"U\", \"T\")\n",
    "\n",
    "def reverse_complement(seq: str) -> str:\n",
    "    return str(Seq(seq).reverse_complement())\n",
    "\n",
    "def replace_central(seq: str, new_codon=\"TAG\", central_pos=76) -> str:\n",
    "    return seq[:central_pos] + new_codon + seq[central_pos+3:]\n",
    "\n",
    "def insert_MS2_loops(seq: str, MS2_dict: dict) -> str:\n",
    "    \"\"\"Insert all MS2 loops in one pass using offsets to account for growth.\"\"\"\n",
    "    s = seq\n",
    "    offset = 0\n",
    "    for pos in sorted(MS2_dict.keys()):\n",
    "        insert = MS2_dict[pos].upper()\n",
    "        s = s[:pos+offset] + insert + s[pos+offset+5:]  # replace 5 nt at pos with 21-nt insert\n",
    "        offset += len(insert) - 5\n",
    "    return s\n",
    "\n",
    "def replace_in_frame_stops(seq: str, central_TAG_pos: int) -> str:\n",
    "    \"\"\"Replace other in-frame stops (frame 0) except the central TAG at central_TAG_pos.\"\"\"\n",
    "    seq_list = list(seq)\n",
    "    for i in range(0, len(seq)-2, 3):\n",
    "        if i == central_TAG_pos:\n",
    "            continue\n",
    "        codon = \"\".join(seq_list[i:i+3])\n",
    "        if codon == \"TAG\":\n",
    "            seq_list[i:i+3] = list(\"CAG\")\n",
    "        elif codon == \"TAA\":\n",
    "            seq_list[i:i+3] = list(\"TCA\")\n",
    "        elif codon == \"TGA\":\n",
    "            seq_list[i:i+3] = list(\"GGA\")\n",
    "    return \"\".join(seq_list)\n",
    "\n",
    "def replace_in_frame_ATG(seq: str) -> str:\n",
    "    \"\"\"Replace in-frame ATG -> ATT (frame 0).\"\"\"\n",
    "    seq_list = list(seq)\n",
    "    for i in range(0, len(seq)-2, 3):\n",
    "        codon = \"\".join(seq_list[i:i+3])\n",
    "        if codon == \"ATG\":\n",
    "            seq_list[i:i+3] = list(\"ATT\")\n",
    "    return \"\".join(seq_list)\n",
    "\n",
    "def contains_forbidden_sites(seq: str) -> bool:\n",
    "    for site in FORBIDDEN_SITES:\n",
    "        if site in seq:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def translate_seq(full_seq: str, central_tag_pos: int = None) -> str:\n",
    "    \"\"\"Translate full_seq in-frame (frame 0). Mark central TAG (if present) as '*' at given index.\"\"\"\n",
    "    aa = []\n",
    "    for i in range(0, len(full_seq)-2, 3):\n",
    "        codon = full_seq[i:i+3]\n",
    "        if central_tag_pos is not None and i == central_tag_pos:\n",
    "            aa.append(\"*\")\n",
    "        else:\n",
    "            aa.append(str(Seq(codon).translate()))\n",
    "    return \"\".join(aa)\n",
    "\n",
    "def classify_region(start_pos: int, seq_len: int, X: int, Y: int, Z: int) -> str:\n",
    "    \"\"\"Classify where the extracted window (start_pos ... start_pos+seq_len-1) maps to [X,Y,Z].\"\"\"\n",
    "    end_pos = start_pos + seq_len - 1\n",
    "    U5_end = X - 1\n",
    "    ORF_start = X\n",
    "    ORF_end = X + Y - 1\n",
    "    U3_start = X + Y\n",
    "    U3_end = X + Y + Z - 1\n",
    "\n",
    "    # booleans for overlap - use inclusive coords\n",
    "    in_5U = start_pos >= 0 and end_pos <= U5_end\n",
    "    in_5U_ORF = start_pos <= U5_end and end_pos >= ORF_start and end_pos <= ORF_end\n",
    "    in_ORF = start_pos >= ORF_start and end_pos <= ORF_end\n",
    "    in_ORF_3U = start_pos >= ORF_start and start_pos <= ORF_end and end_pos >= U3_start\n",
    "    in_3U = start_pos >= U3_start and end_pos <= U3_end\n",
    "    in_all = start_pos <= U5_end and end_pos >= U3_start\n",
    "\n",
    "    if in_5U:\n",
    "        return \"5U\"\n",
    "    elif in_5U_ORF:\n",
    "        return \"5U-ORF\"\n",
    "    elif in_ORF:\n",
    "        return \"ORF\"\n",
    "    elif in_ORF_3U:\n",
    "        return \"ORF-3U\"\n",
    "    elif in_3U:\n",
    "        return \"3U\"\n",
    "    elif in_all:\n",
    "        return \"5U-ORF-3U\"\n",
    "    else:\n",
    "        return \"UNCLASSIFIED\"\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare adapters\n",
    "# -----------------------------\n",
    "prefix = (user_prefix.upper() if user_prefix else default_prefix.upper())\n",
    "suffix = (user_suffix.upper() if user_suffix else default_suffix.upper())\n",
    "# Validate adapters (will raise if invalid)\n",
    "check_adapter_validity(prefix, \"Prefix\")\n",
    "check_adapter_validity(suffix, \"Suffix\")\n",
    "\n",
    "# -----------------------------\n",
    "# Main processing loop\n",
    "# -----------------------------\n",
    "design_records = []\n",
    "csv_records = []\n",
    "skipped_records = []\n",
    "\n",
    "for record in SeqIO.parse(input_fasta, \"fasta\"):\n",
    "    rna_name = record.id                     # e.g., Trat1 (used for label)\n",
    "    description = record.description         # full header line, contains [X,Y,Z]\n",
    "    seq_orig = dna_standardize(str(record.seq))\n",
    "\n",
    "    # Parse X,Y,Z from description - allow optional spaces\n",
    "    match = re.search(r\"\\[(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\]\", description)\n",
    "    if not match:\n",
    "        skipped_records.append(f\"{rna_name}: missing [X,Y,Z] annotation\")\n",
    "        continue\n",
    "    X, Y, Z = map(int, match.groups())\n",
    "\n",
    "    # Find all CCA sites\n",
    "    for m in re.finditer(\"CCA\", seq_orig):\n",
    "        start_c = m.start()  # 0-indexed position of the first 'C' in CCA in the original mRNA\n",
    "\n",
    "        # Extract Â±76 nt (76 left, CCA, 76 right) => total 155 nt\n",
    "        left = start_c - 76\n",
    "        right = start_c + 3 + 76\n",
    "        if left < 0 or right > len(seq_orig):\n",
    "            skipped_records.append(f\"{rna_name}_{start_c}: incomplete flanking sequences\")\n",
    "            continue\n",
    "        sub_seq = seq_orig[left:right]  # length should be 155\n",
    "        if len(sub_seq) != 155:\n",
    "            skipped_records.append(f\"{rna_name}_{start_c}: extracted length != 155 ({len(sub_seq)})\")\n",
    "            continue\n",
    "\n",
    "        # Region classification (based on where this 155-nt window starts in original mRNA)\n",
    "        region_class = classify_region(left, len(sub_seq), X, Y, Z)\n",
    "\n",
    "        # Reverse complement => central triplet should be TGG (revcomp of CCA)\n",
    "        sub_seq = reverse_complement(sub_seq)\n",
    "        if sub_seq[76:79] != \"TGG\":\n",
    "            # Unexpected; skip and log (ensures central TGG as requested)\n",
    "            skipped_records.append(f\"{rna_name}_{start_c}: central codon not TGG after reverse complement (found '{sub_seq[76:79]}')\")\n",
    "            continue\n",
    "\n",
    "        # Change central TGG -> TAG at positions 76-78 (0-indexed)\n",
    "        sub_seq = replace_central(sub_seq, new_codon=\"TAG\", central_pos=76)\n",
    "\n",
    "        # Insert MS2 loops at positions 21,47,103,129 (single-step with offset)\n",
    "        sub_seq = insert_MS2_loops(sub_seq, MS2_inserts)\n",
    "\n",
    "        # After insertions, central TAG should be at 108 (0-indexed)\n",
    "        central_TAG_pos = 108\n",
    "\n",
    "        # Replace other in-frame stops (frame 0) except central TAG\n",
    "        sub_seq = replace_in_frame_stops(sub_seq, central_TAG_pos)\n",
    "\n",
    "        # Replace in-frame ATG -> ATT\n",
    "        sub_seq = replace_in_frame_ATG(sub_seq)\n",
    "\n",
    "        # Append adapters\n",
    "        full_seq = prefix + sub_seq + suffix\n",
    "\n",
    "        # Final forbidden-site check (BspQI/SapI)\n",
    "        if contains_forbidden_sites(full_seq):\n",
    "            skipped_records.append(f\"{rna_name}_{start_c}: BspQI/SapI site detected after modifications\")\n",
    "            continue\n",
    "\n",
    "        # Translate sequence and mark central TAG as '*' (central position in full_seq)\n",
    "        aa_seq = translate_seq(full_seq, central_tag_pos = len(prefix) + central_TAG_pos)\n",
    "\n",
    "        # Label format requested: f\"{rna_name}_{idx}\" where idx is 0-indexed first C of CCA\n",
    "        label = f\"{rna_name}_{start_c}\"\n",
    "\n",
    "        # Save sequences and csv metadata\n",
    "        design_records.append(SeqRecord(Seq(full_seq), id=label, description=\"\"))\n",
    "        csv_records.append({\n",
    "            \"label\": label,\n",
    "            \"full_seq\": full_seq,\n",
    "            \"aa_seq\": aa_seq,\n",
    "            \"region_class\": region_class\n",
    "        })\n",
    "\n",
    "# -----------------------------\n",
    "# Write outputs\n",
    "# -----------------------------\n",
    "# FASTA (accepted designs)\n",
    "SeqIO.write(design_records, output_fasta, \"fasta\")\n",
    "\n",
    "# CSV with columns: label, full_seq, aa_seq, region_class\n",
    "df = pd.DataFrame(csv_records, columns=[\"label\",\"full_seq\",\"aa_seq\",\"region_class\"])\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Skipped log\n",
    "with open(skipped_log, \"w\") as fh:\n",
    "    for line in skipped_records:\n",
    "        fh.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Processed designs: {len(design_records)}\")\n",
    "print(f\"Skipped entries: {len(skipped_records)} (see {skipped_log})\")\n",
    "print(f\"Wrote FASTA: {output_fasta}\")\n",
    "print(f\"Wrote CSV: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce29f2d-1aa2-4ccb-a248-6f57ced414ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015445d-36f7-43db-950a-750b2fda3cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859daa5c-fd0e-4199-b003-a16f38fe6adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721e894-cdde-4a8e-85ec-4de84fe77507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917174e-0218-47b7-be5c-576b0f417a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d43438-d1a9-4818-960e-ff9fe1a81a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced0640-fb08-4df6-ac2b-907f82dc9294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
